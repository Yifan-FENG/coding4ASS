{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome the tutorial session of block IV!\n",
    "\n",
    "**General announcements**\n",
    "\n",
    "* Exam: MON, October 21 4.15 - 7.00pm - check!\n",
    "* Resit assignment (to make up for one assignment, max grade 7.5): Friday, October 25\n",
    "* Decision about resit assignment: end of next week (October 17/18)\n",
    "* Resit exam: date will be communicated\n",
    "\n",
    "**Questions about general things?**\n",
    "\n",
    "**Q and A assignment IV can be found [here](https://docs.google.com/document/d/1ebXRAEzkcBwowpcYf-6n_FM3UdwpZCXOvhH8Kd0bAfU/edit?usp=sharing)**\n",
    "\n",
    "\n",
    "**A bit of myth-busting:**\n",
    "\n",
    "Do I have to be part of some small elite of brilliant people to become a good programmer?\n",
    "\n",
    "[Article on the history of programming and how it acquired prestige](https://www.nytimes.com/2019/02/13/magazine/women-coding-computer-programming.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for today \n",
    "\n",
    "* Understanding data and directory strucutures - a toy example of a parallel corpus\n",
    "* Extracting infromation from nested containers: either json or tsv (list of dicts) \n",
    "* XML if there are questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions about material & assignment\n",
    "\n",
    "\n",
    "* [fill in here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding data and directory structures\n",
    "\n",
    "\n",
    "**Coverage of a parallel corpus**\n",
    "\n",
    "Toy parallel corpus: `parallel_corpus/[doc_name]/[language].txt`\n",
    "\n",
    "Parallel data: same data in multiple languages (--> automatic translation, language comparison, etc)\n",
    "\n",
    "* How many documents exist for German and English?\n",
    "* How many documents exist for English and Dutch?\n",
    "* How many documents exist for German and Dutch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel_corpus/doc1/en.txt\n",
      "parallel_corpus/doc1/de.txt\n",
      "parallel_corpus/doc3/en.txt\n",
      "parallel_corpus/doc3/nl.txt\n",
      "parallel_corpus/doc2/en.txt\n",
      "parallel_corpus/doc2/de.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "corpus_path = 'parallel_corpus/'\n",
    "\n",
    "document_paths = glob.glob(f'{corpus_path}*/*.txt')\n",
    "for doc_path in document_paths:\n",
    "    print(doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting information from a filepath**\n",
    "\n",
    "Tip: String methods are your friend!\n",
    "\n",
    "* What part of the filepath contains the document name?\n",
    "* What part of the filepath contains the language? \n",
    "* How can we extract these parts of the filepath?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1\n"
     ]
    }
   ],
   "source": [
    "test_document = document_paths[0]\n",
    "print(test_document.split('/')[-2])\n",
    "# split\n",
    "# use slicing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more nexted structures with JSON\n",
    "\n",
    "**How to explore a file whose structure you don't understand yet?**\n",
    "\n",
    "* Step 1: Get a gloabl idea of what the file contains\n",
    "* Step 2: Get an idea of the structure and how it may work\n",
    "* Step 3: Test your assumptions and adapt if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "stranger_things_path = '../../python-for-text-analysis/Data/\\\n",
    "json_data/StrangerThings.json'\n",
    "\n",
    "with open (stranger_things_path) as infile:\n",
    "    stranger_data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter One: The Vanishing of Will Byers 1\n",
      "Chapter Two: The Weirdo on Maple Street 1\n",
      "Chapter Three: Holly, Jolly 1\n",
      "Chapter Four: The Body 1\n",
      "Chapter Five: The Flea and the Acrobat 1\n",
      "Chapter Six: The Monster 1\n",
      "Chapter Seven: The Bathtub 1\n",
      "Chapter Eight: The Upside Down 1\n",
      "Chapter One: MADMAX 2\n",
      "Chapter Two: Trick or Treat, Freak 2\n",
      "Chapter Three: The Pollywog 2\n",
      "Chapter Four: Will the Wise 2\n",
      "Chapter Five: Dig Dug 2\n",
      "Chapter Six: The Spy 2\n",
      "Chapter Seven: The Lost Sister 2\n",
      "Chapter Eight: The Mind Flayer 2\n",
      "Chapter Nine: The Gate 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "episode_list =  stranger_data['_embedded']['episodes']\n",
    "\n",
    "for episode_dict in episode_list:\n",
    "    print(episode_dict['name'], episode_dict['season'])\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n"
     ]
    }
   ],
   "source": [
    "print(stranger_data['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing information in a nested structure\n",
    "\n",
    "Print the following information about the TV show:\n",
    "\n",
    "* the language \n",
    "* the summary \n",
    "* the genres \n",
    "* the average rating\n",
    "* the number of episodes\n",
    "* [difficult] the number of seasons\n",
    "* the url of the original image of the TV show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information from a list of dicts\n",
    "\n",
    "Table of female oscar winners (look at the file in a spreadsheet editor)\n",
    "\n",
    "### CSV/TSV exercise (similar to exercise 2 assignment 4a):\n",
    "\n",
    "**Extracting data**\n",
    "* Who was the youngest winner and how old was she when she won? Can we use min() for this? Why (not)?\n",
    "* How many actresses won in more than one year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1\n",
      "Year 1928\n",
      "Age 22\n",
      "Name Janet Gaynor\n",
      "Movie Seventh Heaven, Street Angel and Sunrise: A Song of Two Humans\n",
      "\n",
      "Index 2\n",
      "Year 1929\n",
      "Age 37\n",
      "Name Mary Pickford\n",
      "Movie Coquette\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading in the file as a list of dicts\n",
    "with open('../blockIV-lecture1/Data/oscars_female.tsv') as infile:\n",
    "    text = infile.read().strip()\n",
    "    \n",
    "lines = text.split('\\n')\n",
    "\n",
    "oscar_dict_list = []\n",
    "headers = lines[0].split('\\t')\n",
    "\n",
    "for line in lines[1:]:\n",
    "    line_list = line.split('\\t')\n",
    "    line_dict = dict()\n",
    "    for header, cell in zip(headers, line_list):\n",
    "        line_dict[header] = cell\n",
    "    oscar_dict_list.append(line_dict)\n",
    "    \n",
    "for line_dict in oscar_dict_list[0:2]:\n",
    "    for k, v in line_dict.items():\n",
    "        print(k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Jessica Tandy\n"
     ]
    }
   ],
   "source": [
    "# Who is the youngest actress who won an oscar?\n",
    "\n",
    "\n",
    "age_actresses = []\n",
    "\n",
    "highest_age = 0\n",
    "oldest_actress = ''\n",
    "\n",
    "for oscar_dict in oscar_dict_list:\n",
    "    age = int(oscar_dict['Age'])\n",
    "    name = oscar_dict['Name']\n",
    "    if age > highest_age:\n",
    "        highest_age = age\n",
    "        oldest_actress = name\n",
    "        \n",
    "print(highest_age, oldest_actress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string: yes\n",
      "list: no\n",
      "tokenized text (list): no\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "my_text = 'Hi there, how many more iterations do we need?'\n",
    "my_text_list = my_text.split(' ')\n",
    "tokens = word_tokenize(my_text)\n",
    "\n",
    "\n",
    "search_term = 'it'\n",
    "if search_term in my_text:\n",
    "    print('string: yes')\n",
    "else:\n",
    "    print('string: no')\n",
    "    \n",
    "    \n",
    "search_term = 'need'\n",
    "if search_term in my_text_list:\n",
    "    print('list: yes')\n",
    "else:\n",
    "    print('list: no')\n",
    "    \n",
    "search_term = 'it' # 'need' works now\n",
    "\n",
    "if search_term in tokens:\n",
    "    print('tokenized text (list): yes')\n",
    "else:\n",
    "    print('tokenized text (list): no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who won in more than one year?\n",
    "\n",
    "import operator\n",
    "\n",
    "oscar_counter = dict()\n",
    "\n",
    "for oscar_dict in oscar_dicts:\n",
    "    actress = oscar_dict['Name']\n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "for winner, count in sorted(oscar_counter.items(),\n",
    "                            key=operator.itemgetter(1),\n",
    "                            reverse=True):\n",
    "    #print(winner, count)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting infromation from an xml file\n",
    "\n",
    "**Course directory in xml structure (wsu.xml)**\n",
    "\n",
    "* How is a single course represented?\n",
    "* What infromation is given about a single course?\n",
    "* Are the data consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element root at 0x110284908>\n",
      "<Element course at 0x110247a48>\n",
      "<course>\n",
      "  <footnote/>\n",
      "  <sln>10637</sln>\n",
      "  <prefix>ACCTG</prefix>\n",
      "  <crs>230</crs>\n",
      "  <lab/>\n",
      "  <sect>01</sect>\n",
      "  <title>INT FIN ACCT</title>\n",
      "  <credit>3.0</credit>\n",
      "  <days>TU,TH</days>\n",
      "  <times>\n",
      "     <start>7:45</start>\n",
      "     <end>9</end>\n",
      "  </times>\n",
      "  <place>\n",
      "      <bldg>TODD</bldg>\n",
      "      <room>230</room>\n",
      "  </place>\n",
      "  <instructor>B. MCELDOWNEY</instructor>\n",
      "  <limit>0112</limit>\n",
      "  <enrolled>0108</enrolled>\n",
      "</course>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Exploring an xml file - start by looking at a single element\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "course_tree = etree.parse('../blockIV-lecture1/Data/wsu.xml')\n",
    "root = course_tree.getroot()\n",
    "print(root)\n",
    "\n",
    "# We already know that the immediate children of the root are the course-elements\n",
    "#courses = root.getchildren()\n",
    "\n",
    "course1 = root.find('course')\n",
    "print(course1)\n",
    "\n",
    "etree.dump(course1, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all start and end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print whether a course is fill or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
