{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to block IV!\n",
    "\n",
    "**Well done on blocks 2 and 3 - you've come really far!**\n",
    "\n",
    "**General announcements**\n",
    "\n",
    "* Attention - material has been updated (see Canvas announcement)\n",
    "* Please no emails with screenshots\n",
    "* Get used to debugging your code - it is part of being an independet programmer ;-)\n",
    "\n",
    "**Questions about general things?**\n",
    "\n",
    "**Questions about block IV?**\n",
    "\n",
    "**A bit of myth-busting:**\n",
    "\n",
    "Do I have to be part of some small elite of brilliant people to become a good programmer?\n",
    "\n",
    "[Article on the history of programming and how it acquired prestige](https://www.nytimes.com/2019/02/13/magazine/women-coding-computer-programming.html)\n",
    "\n",
    "**Q and A assignment IV can be found [here](https://docs.google.com/document/d/1ebXRAEzkcBwowpcYf-6n_FM3UdwpZCXOvhH8Kd0bAfU/edit?usp=sharing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics and schedule\n",
    "\n",
    "* Intro to data formats\n",
    "* How to deal with nested structures\n",
    "* Understanding the CSV/TSV format\n",
    "* More nesting with JSON\n",
    "* Introduction to XML\n",
    "\n",
    "**Schedule**\n",
    "\n",
    "part 1: 3.30 - 4.15\n",
    "\n",
    "* Intro\n",
    "* Nested structures\n",
    "* CSV-TSV\n",
    "\n",
    "part 2: 4.30 - 5.15\n",
    "\n",
    "* JSON\n",
    "* XML \n",
    "\n",
    "Monday:\n",
    "\n",
    "* Whatever is left over from today\n",
    "* A closer look at xml\n",
    "* Approaching a larger task (i.e. multiple files, etc)\n",
    "* Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Intro to data formats \n",
    "\n",
    "**What does 'structured data' mean?** \n",
    "\n",
    "**Example: result of assignment 3b**\n",
    "\n",
    "* Task: write top 20 nouns to a text file in which each word is on a new line\n",
    "* How can we read in those 20 words?\n",
    "* Would it be possible to write a general function for all three books? \n",
    "* Consistent regularities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levin\n",
      "Vronsky\n",
      "Anna\n",
      "time\n",
      "Alexey\n",
      "hand\n",
      "Kitty\n",
      "eye\n",
      "Stepan\n",
      "face\n",
      "Alexandrovitch\n",
      "man\n",
      "Arkadyevitch\n",
      "nothing\n",
      "life\n",
      "day\n",
      "something\n",
      "word\n",
      "thing\n"
     ]
    }
   ],
   "source": [
    "with open('Data/top_20_AnnaKarenina.txt') as infile:\n",
    "    top_20_nouns = infile.read()\n",
    "    \n",
    "# What now?\n",
    "print(top_20_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different levels of structure\n",
    "\n",
    "* transparent, easy to deal with using the standard library: csv, tsv\n",
    "* more complicated, best dealt with using specific python modules: xml, json\n",
    "\n",
    "**... theoretically, you can always just read in a file and exploit its regularities**\n",
    "\n",
    "#### Overview\n",
    "\n",
    "| format  | read in                          | write                                  | package    | python structure |\n",
    "|---------|----------------------------------|----------------------------------------|------------|------------------|\n",
    "| csv/tsv | context manager +file.read()     | context manager +file.write()          | none       | list of dicts    |\n",
    "| json    | context manager +json.load(file) | context manager +json.dump(dict, file) | json       | nested dict      |\n",
    "| xml     | etree.parse(path)                | context manager + tree.write(file)     | lxml.etree | lxml etree         |\n",
    "\n",
    "\n",
    "### How to deal with data formats - general workflow\n",
    "\n",
    "1.) Open and read in the file\n",
    "\n",
    "2.) Store content in a python container that suits your purposes\n",
    "\n",
    "3.) Access/extract/manipulate data you need \n",
    "\n",
    "4.) Store results in a new file \n",
    "\n",
    "5.) Debug\n",
    "    (because you made the wrong assumptions ;-)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nested Structures\n",
    "\n",
    "* access items in a list\n",
    "* access keys and values in a dict\n",
    "* deal with nested structures and loops \n",
    "\n",
    "**How many levels can we nest?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesting \n",
    "\n",
    "person_list = [\n",
    "            {'name': 'Tom', 'favorite_color': 'black', 'age': 14, 'pets': ['cat']},\n",
    "            {'name': 'Anna', 'favorite_color': 'blue', 'age': 24, 'pets': ['snake', 'spider']},\n",
    "            {'name': 'Emma', 'favorite_color': 'green', 'age': 28, 'pets': []},\n",
    "            {'name': 'David', 'favorite_color': 'yellow', 'age': 28, 'pets': ['cat']}\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': ['Tom', 'David'], 'snake': ['Anna'], 'spider': ['Anna']}\n"
     ]
    }
   ],
   "source": [
    "pet_dict = dict()\n",
    "\n",
    "for person_dict in person_list:\n",
    "    pet_list = person_dict['pets']\n",
    "    for pet in pet_list:\n",
    "        if pet not in pet_dict:\n",
    "            pet_dict[pet] = [person_dict['name']]\n",
    "        else:\n",
    "            pet_dict[pet].append(person_dict['name'])\n",
    "print (pet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snake\n"
     ]
    }
   ],
   "source": [
    "# get Anna's favorite color in 1 line:\n",
    "print(person_list[1]['pets'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "14\n",
      "\n",
      "True\n",
      "24\n",
      "\n",
      "False\n",
      "28\n",
      "\n",
      "False\n",
      "28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print all ages \n",
    "\n",
    "for person_dict in person_list:\n",
    "    print(person_dict['name'].startswith('A'))\n",
    "    print(person_dict['age'])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of pets for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the [pet] belongs to [name] (one line per pet)'\n",
    "a = [1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat <class 'list'> ['Tom']\n",
      "snake <class 'list'> ['Anna']\n",
      "spider <class 'list'> ['Anna']\n"
     ]
    }
   ],
   "source": [
    "# new dict with pets as keys and a list of people who own it as values\n",
    "\n",
    "pet_dict = dict()\n",
    "\n",
    "for person_dict in person_list:\n",
    "    pet_list = person_dict['pets']\n",
    "    for pet in pet_list:\n",
    "        if pet not in pet_dict:\n",
    "            pet_dict[pet] = [person_dict['name']]\n",
    "        else:\n",
    "            pet_dict[pet].append(person_dict['name'])\n",
    "        \n",
    "    \n",
    "#print(pet_dict)\n",
    "for k, v in pet_dict.items():\n",
    "    print(k, type(v), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) CSV and TSV \n",
    "\n",
    "\n",
    "### 3.a) Reading in a TSV file\n",
    "\n",
    "Let's conider the file 'oscars_female.csv':\n",
    "\n",
    "* Content? Structure?\n",
    "* What is a good format for storing csv/tsv data in python? In other words: What do we usually want to know about cells in a table? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3\\t1930\\t28\\tNorma Shearer\\tThe Divorcee'\n"
     ]
    }
   ],
   "source": [
    "with open('Data/oscars_female.tsv') as infile:\n",
    "    text = infile.read().strip()\n",
    "    \n",
    "lines = text.split('\\n')\n",
    "\n",
    "\n",
    "for line in lines[3:4]:\n",
    "    print(repr(line))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary Pickford\n"
     ]
    }
   ],
   "source": [
    "# read in with lines as lists\n",
    "\n",
    "oscar_lists = []\n",
    "\n",
    "for line in lines:\n",
    "    line_list = line.split('\\t')\n",
    "    oscar_lists.append(line_list)\n",
    "    \n",
    "\n",
    "    \n",
    "print(oscar_lists[2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n",
      "c 3\n"
     ]
    }
   ],
   "source": [
    "a = ['a', 'b', 'c']\n",
    "b = [1,2,3]\n",
    "\n",
    "for char, num in zip(a, b):\n",
    "    print(char, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1\n",
      "Year 1928\n",
      "Age 22\n",
      "Name Janet Gaynor\n",
      "Movie Seventh Heaven, Street Angel and Sunrise: A Song of Two Humans\n",
      "\n",
      "Index 2\n",
      "Year 1929\n",
      "Age 37\n",
      "Name Mary Pickford\n",
      "Movie Coquette\n",
      "\n",
      "Index 3\n",
      "Year 1930\n",
      "Age 28\n",
      "Name Norma Shearer\n",
      "Movie The Divorcee\n",
      "\n",
      "Index 4\n",
      "Year 1931\n",
      "Age 63\n",
      "Name Marie Dressler\n",
      "Movie Min and Bill\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in with lines as dicts + a bit of debugging\n",
    "\n",
    "# error - point out a very nice string method :-) \n",
    "\n",
    "oscar_dict_list = []\n",
    "\n",
    "headers = lines[0].split('\\t')\n",
    "\n",
    "\n",
    "for line in lines[1:]:\n",
    "    line_list = line.split('\\t')\n",
    "    line_dict = dict()\n",
    "    for header, cell in zip(headers, line_list):\n",
    "        line_dict[header] = cell\n",
    "    oscar_dict_list.append(line_dict)\n",
    "    \n",
    "for line_dict in oscar_dict_list[0:4]:\n",
    "    for k, v in line_dict.items():\n",
    "        print(k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "strip(self, chars=None, /)\n",
      "    Return a copy of the string with leading and trailing whitespace remove.\n",
      "    \n",
      "    If chars is given and not None, remove characters in chars instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-729f5a8fbbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mline_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "# Improved solution\n",
    "\n",
    "oscar_dicts = []\n",
    "\n",
    "\n",
    "for line in lines[1:5]:\n",
    "    line_list = line.split('\\t')\n",
    "    pass \n",
    "    \n",
    "for oscar_dict in oscar_dicts[:4]:\n",
    "    print(oscar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in with lines as dicts and get header from first line\n",
    "# turn into a fucntion so we can reuse it :-) \n",
    "# what arguments should we define? \n",
    "\n",
    "def read_csv_tsv():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b.) Writing a list of dicts to a tsv file\n",
    "\n",
    "Write a new tsv file with only names and years. \n",
    "\n",
    "Tips:\n",
    "\n",
    "* Write file line by line (as you did with the text files)\n",
    "* Get headers (usually in a list)\n",
    "* Get cells per line (usually in a list)\n",
    "* Write header/line as string (--> list to string)\n",
    "* Do not forget to add new-line charaters at the end of a line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "\n",
    "# get header\n",
    "\n",
    "with open('Data/oscar_winners_years.tsv', 'w') as outfile:\n",
    "    # write header\n",
    "    for oscar_dict in oscar_dicts:\n",
    "        #write lines\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [If time]\n",
    "### CSV/TSV exercise (similar to exercise 2):\n",
    "\n",
    "\n",
    "**Extracting data**\n",
    "- How many actresses won in more than one year?\n",
    "- Who was the youngest winner and how old was she when she won? Can we use min() for this? Why (not)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people won oscars in more than one year?\n",
    "import operator\n",
    "\n",
    "oscar_counter = dict()\n",
    "\n",
    "for oscar_dict in oscar_dicts:\n",
    "    actress = oscar_dict['Name']\n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "for winner, count in sorted(oscar_counter.items(),\n",
    "                            key=operator.itemgetter(1),\n",
    "                            reverse=True):\n",
    "    #print(winner, count)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Dealing with JSON\n",
    "\n",
    "- nice, lightweight dataformat\n",
    "- across platforms and languages - really well compatiple with python!\n",
    "- nicer for nested information (see multiple movie titles in csv/tsv...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we explore a .json file?\n",
    "\n",
    "What is in the StrangerThings json?\n",
    "\n",
    "* manual inspection (editor)    \n",
    "* python code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "stranger_things_path = '../python-for-text-analysis/Data/\\\n",
    "json_data/StrangerThings.json'\n",
    "\n",
    "with open (stranger_things_path) as infile:\n",
    "    stranger_data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "id <class 'int'>\n",
      "url <class 'str'>\n",
      "name <class 'str'>\n",
      "type <class 'str'>\n",
      "language <class 'str'>\n",
      "genres <class 'list'>\n",
      "status <class 'str'>\n",
      "runtime <class 'int'>\n",
      "premiered <class 'str'>\n",
      "officialSite <class 'str'>\n",
      "schedule <class 'dict'>\n",
      "rating <class 'dict'>\n",
      "weight <class 'int'>\n",
      "network <class 'NoneType'>\n",
      "webChannel <class 'dict'>\n",
      "externals <class 'dict'>\n",
      "image <class 'dict'>\n",
      "summary <class 'str'>\n",
      "updated <class 'int'>\n",
      "_links <class 'dict'>\n",
      "_embedded <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(stranger_data))\n",
    "for k, v in stranger_data.items():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger Things\n"
     ]
    }
   ],
   "source": [
    "print(stranger_data['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json exercise\n",
    "\n",
    "Print the following information about the TV show:\n",
    "* the language \n",
    "* the summary \n",
    "* the genres \n",
    "* the average rating\n",
    "* the number of episodes\n",
    "* [difficult] the number of seasons\n",
    "* the url of the original image of the TV show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Get number of episodes/number of seasons \n",
    "for k, v in stranger_data['_embedded'].items():\n",
    "    print(k, type(v))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Getting started with XML\n",
    "\n",
    "\n",
    "1.) Explore file in an editor\n",
    "\n",
    "2.) Check if we can access the different levels of information\n",
    "\n",
    "3.) Extract infromation\n",
    "\n",
    "\n",
    "### LXML etree \n",
    "\n",
    "\n",
    "**Elements of an xml-tree**\n",
    "\n",
    "* xml elements\n",
    "* root element\n",
    "* children ('subelements')\n",
    "* levels \n",
    "* tags\n",
    "* attributes\n",
    "* text\n",
    "\n",
    "**Exploring the data and extracting information**\n",
    "\n",
    "* load a file as an xml tree: `etree.parse(path)`\n",
    "* get the root element: `tree.getroot()`\n",
    "* get a list of all 'subelements' of an element: `element.getchildren()`\n",
    "* get the first element with a particular tag: `tree.find(tag-string)`\n",
    "* get the tag label: `element.tag`\n",
    "* get the text of an element: `element.text`\n",
    "* get attribute: `element.get(attribute label)`\n",
    "* get all attributes + values: `element.attrib` or `element.items()`) \n",
    "(Can you tell the difference?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error reading file '../python-for-text-analysis/Data/xml_data/course.xml': failed to load external entity \"../python-for-text-analysis/Data/xml_data/course.xml\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-532fea5c77c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlxml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../python-for-text-analysis/Data/xml_data/course.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocumentFromURL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._raiseParseError\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Error reading file '../python-for-text-analysis/Data/xml_data/course.xml': failed to load external entity \"../python-for-text-analysis/Data/xml_data/course.xml\""
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "tree = etree.parse('../python-for-text-analysis/Data/xml_data/course.xml')\n",
    "root = tree.getroot()\n",
    "print('root', type(root), root)\n",
    "print()\n",
    "print('etree.dump example')\n",
    "etree.dump(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element person at 0x111bd3c08> person coordinator Van der Vliet <class 'str'>\n",
      "<Element person at 0x111b8c8c8> person instructor Van Miltenburg <class 'str'>\n",
      "<Element person at 0x111b8c788> person instructor Van Son <class 'str'>\n",
      "<Element person at 0x111b8c448> person instructor Marten Postma <class 'str'>\n",
      "<Element person at 0x111b8c548> person student Baloche <class 'str'>\n",
      "<Element person at 0x111b8ca48> person student De Boer <class 'str'>\n",
      "<Element person at 0x111b8c748> person student Van Doorn <class 'str'>\n",
      "<Element person at 0x111b8c608> person student De Jager <class 'str'>\n",
      "<Element person at 0x111b8c6c8> person student King <class 'str'>\n",
      "<Element person at 0x111b8c588> person student Kingham <class 'str'>\n",
      "<Element person at 0x111b8c7c8> person student Mózes <class 'str'>\n",
      "<Element person at 0x111b8c4c8> person student Rübsaam <class 'str'>\n",
      "<Element person at 0x111b8c408> person student Torsi <class 'str'>\n",
      "<Element person at 0x111b8c508> person student Witteman <class 'str'>\n",
      "<Element person at 0x111b8c388> person student Wouterse <class 'str'>\n",
      "<Element person at 0x111b8c488> person None None <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "people = tree.findall('person')\n",
    "\n",
    "for person in people:\n",
    "    print(person, person.tag, person.get('role'), person.text, type(person.text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise:\n",
    "\n",
    "Example: course directory from Washington State University\n",
    "\n",
    "1.) Exmplore structure, access different levels of information\n",
    "\n",
    "2.) Extract specific information:\n",
    "\n",
    "* Get all course titles\n",
    "* How many courses take place on Thursdays? \n",
    "* How many courses are full?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element root at 0x1081eea08>\n",
      "<Element course at 0x1081ee608>\n",
      "<course>\n",
      "  <footnote/>\n",
      "  <sln>10637</sln>\n",
      "  <prefix>ACCTG</prefix>\n",
      "  <crs>230</crs>\n",
      "  <lab/>\n",
      "  <sect>01</sect>\n",
      "  <title>INT FIN ACCT</title>\n",
      "  <credit>3.0</credit>\n",
      "  <days>TU,TH</days>\n",
      "  <times>\n",
      "     <start>7:45</start>\n",
      "     <end>9</end>\n",
      "  </times>\n",
      "  <place>\n",
      "      <bldg>TODD</bldg>\n",
      "      <room>230</room>\n",
      "  </place>\n",
      "  <instructor>B. MCELDOWNEY</instructor>\n",
      "  <limit>0112</limit>\n",
      "  <enrolled>0108</enrolled>\n",
      "</course>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring an xml file - start by looking at a single element\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "course_tree = etree.parse('Data/wsu.xml')\n",
    "root = course_tree.getroot()\n",
    "print(root)\n",
    "\n",
    "# We already know that the immediate children of the root are the course-elements\n",
    "#courses = root.getchildren()\n",
    "\n",
    "course1 = root.find('course')\n",
    "print(course1)\n",
    "\n",
    "etree.dump(course1, pretty_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT FIN ACCT\n",
      "INT MAN ACCT\n",
      "AG MACH SYST\n",
      "DOCT DISS EX\n",
      "[S] FUND OF MICR\n"
     ]
    }
   ],
   "source": [
    "## Get all course titles\n",
    "\n",
    "for course in courses[:5]:\n",
    "    #print(course.tag, len(course.getchildren()))\n",
    "    for info in course.getchildren():\n",
    "        if info.tag == 'title':\n",
    "            print(info.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT FIN ACCT\n",
      "INT MAN ACCT\n",
      "AG MACH SYST\n",
      "DOCT DISS EX\n",
      "[S] FUND OF MICR\n"
     ]
    }
   ],
   "source": [
    "## Is there a better way?\n",
    "\n",
    "for course in courses[:5]:\n",
    "    #print(course.tag, len(course.getchildren()))\n",
    "    title = course.find('title')\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT FIN ACCT\n",
      "INT MAN ACCT\n",
      "AG MACH SYST\n",
      "DOCT DISS EX\n",
      "[S] FUND OF MICR\n"
     ]
    }
   ],
   "source": [
    "# Is there a better way?\n",
    "\n",
    "for title in root.findall('course/title')[:5]:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort winners by age (starting with the lowest)\n",
    "oscars_age_name = []\n",
    "for oscar_dict in oscar_dicts:\n",
    "    name = oscar_dict['Name']\n",
    "    age = oscar_dict['Age']\n",
    "    oscars_age_name.append((age, name))\n",
    "    \n",
    "    \n",
    "for age, name in sorted(oscars_age_name):\n",
    "    #print(name, age)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q & A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
